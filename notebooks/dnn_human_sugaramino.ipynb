{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b381715",
   "metadata": {},
   "source": [
    "### Build env for this notebook (temp. fix):\n",
    "\n",
    "Running this on CPU with different environment, as tensorflow does not support 5000-series Nvidia GPUs yet.\n",
    "\n",
    "The SVM notebooks have to be executed first, as they create and export the feature data. Then this notebook is run in the dnn_cpu environment, see Readme.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5250fd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826aa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "    RepeatedStratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, make_scorer\n",
    "\n",
    "import seaborn as sns\n",
    "from subpred.evaluation import plot_results_long\n",
    "from subpred.util import save_results, load_data\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9065222",
   "metadata": {},
   "source": [
    "Setting random seeds for all libraries. The seed for TF is a starting seed, and will get incremented with each call of Dropout(). Therefore, the notebook has to be restarted to get the same results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10b8f4",
   "metadata": {},
   "source": [
    "Reading feature data from SVM notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da64614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing feature data from SVM notebooks (they have to be run first)\n",
    "import pickle\n",
    "TEST_NAME = f\"dnn_human_sugaramino\"\n",
    "with open(\"../data/tmp_data/svc_human_sugaramino_ml_data.pickle\", \"rb\") as handle:\n",
    "    ml_datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a420d",
   "metadata": {},
   "source": [
    "Loading SVM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1975b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_svm = load_data(\"../data/results/svc_human_sugaramino.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bf016",
   "metadata": {},
   "source": [
    "Trying three different architectures, as the features have different sizes ranging from 400 to 8000. High dropout of 0.5 should take care of most overfitting problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Test result AT sugar amino: the three models perform very similarly, just use the simplest one (create_model)\n",
    "# Tried different values for dropout (0.0,0.3,0.5,0.7), performance for non-0 is similar.\n",
    "# Dropout 0.5 for smaller datasets, maybe try 0.3 for larger\n",
    "# Tried different values for batch_size. Not really a big difference. 8 for smaller (less overfitting), 16 or 32 for larger (more speed)\n",
    "# TODO put this code into subpred package, once TF is compatible with new GPU\n",
    "\n",
    "\n",
    "def create_model(n_features):\n",
    "    # Larger datasets: try lower dropout\n",
    "    # Try starting at lower number of nodes\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input(shape=(n_features,)),\n",
    "            keras.layers.Dense(512, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(128, activation=\"relu\"),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.F1Score(average=\"macro\", name=\"F1_macro\"),\n",
    "            keras.metrics.TruePositives(name=\"TP\"),\n",
    "            keras.metrics.TrueNegatives(name=\"TN\"),\n",
    "            keras.metrics.FalsePositives(name=\"FP\"),\n",
    "            keras.metrics.FalseNegatives(name=\"FN\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_dynamic_nodes(n_features):\n",
    "    if n_features > 1024:\n",
    "        layer_sizes = [1024, 512, 256]\n",
    "        print(\"selecting large model\")\n",
    "    elif n_features > 512:  # includes embeddings with len 1024\n",
    "        layer_sizes = [512, 256, 128]\n",
    "        print(\"selecting medium model\")\n",
    "    else:\n",
    "        layer_sizes = [256, 128, 64]\n",
    "        print(\"selecting small model\")\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Input(shape=(n_features,)),\n",
    "            keras.layers.Dense(layer_sizes[0], activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(layer_sizes[1], activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(layer_sizes[2], activation=\"relu\"),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.F1Score(average=\"macro\", name=\"F1_macro\"),\n",
    "            keras.metrics.TruePositives(name=\"TP\"),\n",
    "            keras.metrics.TrueNegatives(name=\"TN\"),\n",
    "            keras.metrics.FalsePositives(name=\"FP\"),\n",
    "            keras.metrics.FalseNegatives(name=\"FN\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model_dynamic_layers(n_features):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features,)))\n",
    "    for layer_size in [2048, 1024, 512, 256]:\n",
    "        if n_features >= layer_size:\n",
    "            model.add(keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "            model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.F1Score(average=\"macro\", name=\"F1_macro\"),\n",
    "            keras.metrics.TruePositives(name=\"TP\"),\n",
    "            keras.metrics.TrueNegatives(name=\"TN\"),\n",
    "            keras.metrics.FalsePositives(name=\"FP\"),\n",
    "            keras.metrics.FalseNegatives(name=\"FN\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e84093",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ml_datasets[0].y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45975d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d45f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "def crossval_dnn(\n",
    "    ml_dataset,\n",
    "    model_func,\n",
    "    scores_dict,\n",
    "    splits=5,\n",
    "    repeats=5,\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    verbose=False,\n",
    "    calculate_class_weights=False,\n",
    "):\n",
    "    print(f\"=== {ml_dataset.name} ===\")\n",
    "    preprocess = make_pipeline(VarianceThreshold(0.0), StandardScaler())\n",
    "\n",
    "    X, y = ml_dataset.X, ml_dataset.y\n",
    "\n",
    "    train_scores = list()\n",
    "    test_scores = list()\n",
    "    fold_count = 1\n",
    "    for train_idx_outer, val_idx_outer in RepeatedStratifiedKFold(\n",
    "        n_splits=splits, n_repeats=repeats, random_state=0\n",
    "    ).split(X, y):\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold_count} out of {splits*repeats}\")\n",
    "        fold_count += 1\n",
    "\n",
    "        X_train, X_test = X[train_idx_outer], X[val_idx_outer]\n",
    "        y_train, y_test = y[train_idx_outer], y[val_idx_outer]\n",
    "\n",
    "        X_train = preprocess.fit_transform(X_train, y_train)\n",
    "        X_test = preprocess.transform(X_test)\n",
    "\n",
    "        # important: create from scratch to reset weights\n",
    "        model = model_func(X_train.shape[1])\n",
    "        # TODO Early Stopping can be an option for larger datasets (less overfitting, faster training)\n",
    "        # TODO class weights option\n",
    "        if calculate_class_weights:\n",
    "            classes = np.sort(np.unique(y_train))\n",
    "            class_weights = compute_class_weight(\n",
    "                class_weight=\"balanced\", classes=classes, y=y_train\n",
    "            )\n",
    "            class_weights_dict = dict(zip(classes, class_weights))\n",
    "        training_history = model.fit(\n",
    "            X_train,\n",
    "            y_train.reshape(-1, 1),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=\"auto\" if verbose else 0,\n",
    "            class_weight=class_weights_dict,\n",
    "        )\n",
    "        y_prob = model.predict(X_test, verbose=\"auto\" if verbose else 0)\n",
    "        y_pred = (y_prob > 0.5).astype(int).flatten()\n",
    "        # TODO log mis-classified samples: always the same ones?\n",
    "\n",
    "        for score_name, score_func in scores_dict.items():\n",
    "            test_scores.append(\n",
    "                (ml_dataset.name, score_name, score_func(y_test, y_pred))\n",
    "            )\n",
    "            if verbose:\n",
    "                print(score_name, score_func(y_test, y_pred))\n",
    "\n",
    "        res = model.evaluate(\n",
    "            X_test, y_test.reshape(-1, 1), verbose=\"auto\" if verbose else 0\n",
    "        )\n",
    "        if verbose:\n",
    "            print(res)\n",
    "    df_scores = pd.DataFrame(test_scores, columns=[\"Feature\", \"Metric\", \"Value\"])\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9894e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, ml_dataset in enumerate(ml_datasets):\n",
    "    print(pos, ml_dataset.name, len(ml_dataset.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fc045",
   "metadata": {},
   "source": [
    "Using the same metrics as with the SVM, to compare the results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_outer = {\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "    \"F1 Macro\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, average=\"macro\"\n",
    "    ),\n",
    "    \"F1 Class 0\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, pos_label=0\n",
    "    ),\n",
    "    \"F1 Class 1\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, pos_label=1\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2a78e",
   "metadata": {},
   "source": [
    "Caching of results. A new test always needs a new test_name, otherwise it reads the old results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "if Path(f\"../data/results/{TEST_NAME}.pickle\").exists():\n",
    "    df_results_all = load_data(TEST_NAME, folder_path=\"../data/results\")\n",
    "else:\n",
    "    results = [\n",
    "        crossval_dnn(\n",
    "            ml_dataset=ml_dataset,\n",
    "            model_func=create_model,\n",
    "            scores_dict=scoring_outer,\n",
    "            splits=5,\n",
    "            repeats=5,\n",
    "            epochs=50,\n",
    "            batch_size=8,\n",
    "            calculate_class_weights=True\n",
    "        )\n",
    "        for ml_dataset in ml_datasets\n",
    "    ]\n",
    "    df_results_all = pd.concat(results)\n",
    "    save_results(df_results_all,TEST_NAME, folder_path=\"../data/results\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9f86c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ffc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plot as for svm, to compare\n",
    "df_results_plot = df_results_all.copy()\n",
    "df_results_plot.Feature = df_results_plot.Feature.str.replace(\"_\", \"-\").replace(\"PSSM-META\",\"MULTI-PSSM\")\n",
    "df_results_plot = df_results_plot[~df_results_plot.Feature.str.match(r'^PSSM-\\d+')]\n",
    "df_results_plot = df_results_plot[~df_results_plot.Feature.str.startswith(\"COMB\")]\n",
    "feature_order = [\n",
    "    \"DUMMY\",\n",
    "    \"AAC\",\n",
    "    \"PAAC\",\n",
    "    \"AA-KMER3\",\n",
    "    # \"PSSM-50-1\",\n",
    "    # \"PSSM-50-3\",\n",
    "    # \"PSSM-90-1\",\n",
    "    # \"PSSM-90-3\",\n",
    "    # \"PSSM-META\",\n",
    "    \"MULTI-PSSM\",\n",
    "    \"META\",\n",
    "    \"META-STD\",\n",
    "    \"PROTT5-AA\",\n",
    "    \"PROSTT5-AA\",\n",
    "    \"PROSTT5-3DI\",\n",
    "    \"3Di-COMP\",\n",
    "    \"3Di-KMER2\",\n",
    "    \"3Di-KMER3\",\n",
    "    # \"COMB-KMER1\",\n",
    "    # \"COMB-KMER2\",\n",
    "    # \"COMB-KMER3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_plot.Feature.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4d993",
   "metadata": {},
   "source": [
    "saves plot with test name and metrics in name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_long(\n",
    "    df_results_long=df_results_plot,\n",
    "    output_folder_path=\"../data/results/\",\n",
    "    test_name=TEST_NAME,\n",
    "    plot_order=feature_order,\n",
    "    metrics_include=[\"F1 Class 0\", \"F1 Class 1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c99c1",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff62d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_results_all.copy()\n",
    "df_table.Feature = df_table.Feature.str.replace(\"_\", \"-\").replace(\"PSSM-META\",\"MULTI-PSSM\")\n",
    "df_table = df_table[~df_table.Feature.str.match(r'^PSSM-\\d+')]\n",
    "feature_order = [\n",
    "    \"DUMMY\",\n",
    "    \"AAC\",\n",
    "    \"PAAC\",\n",
    "    \"AA-KMER3\",\n",
    "    # \"PSSM-META\",\n",
    "    \"MULTI-PSSM\",\n",
    "    \"META\",\n",
    "    \"META-STD\",\n",
    "    \"COMB-KMER1\",\n",
    "    \"COMB-KMER2\",\n",
    "    \"COMB-KMER3\",\n",
    "    \"PROTT5-AA\",\n",
    "    \"PROSTT5-AA\",\n",
    "    \"PROSTT5-3DI\",\n",
    "    # \"PSSM-50-1\",\n",
    "    # \"PSSM-50-3\",\n",
    "    # \"PSSM-90-1\",\n",
    "    # \"PSSM-90-3\",\n",
    "    \"3Di-COMP\",\n",
    "    \"3Di-KMER2\",\n",
    "    \"3Di-KMER3\",\n",
    "]\n",
    "\n",
    "df_table_mean = df_table.groupby([\"Feature\", \"Metric\"]).mean().reset_index().pivot(\n",
    "    index=\"Feature\", columns=\"Metric\", values=\"Value\"\n",
    ")\n",
    "df_table_std = df_table.groupby([\"Feature\", \"Metric\"]).std().reset_index().pivot(\n",
    "    index=\"Feature\", columns=\"Metric\", values=\"Value\"\n",
    ")\n",
    "\n",
    "df_table_paper = df_table_mean.map(lambda x: f\"{x:.3f}\").astype(str) + \"Â±\" + df_table_std.map(lambda x: f\"{x:.3f}\").astype(str)\n",
    "df_table_paper = df_table_paper.loc[feature_order]\n",
    "df_table_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_paper.columns.name = None\n",
    "print(\n",
    "    df_table_paper.reset_index(drop=False)\n",
    "    .drop(\"F1 Macro\", axis=1)\n",
    "    .to_latex(index=False)\n",
    "    .replace(\"tabular\", \"tabular*\")\n",
    "    .replace(\"{llll}\", \"{\\\\textwidth}{@{\\\\extracolsep{\\\\fill}} lrrr}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15219298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
