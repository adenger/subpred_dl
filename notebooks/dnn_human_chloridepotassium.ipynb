{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b381715",
   "metadata": {},
   "source": [
    "### Build env for this notebook (temp. fix):\n",
    "\n",
    "Running this on CPU with different environment, as tensorflow does not support 5000-series Nvidia GPUs yet.\n",
    "\n",
    "The SVM notebooks have to be executed first, as they create and export the feature data. Then this notebook is run in the dnn_cpu environment, see Readme.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5250fd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826aa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "from subpred.evaluation import plot_results_long\n",
    "from subpred.util import save_results, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9065222",
   "metadata": {},
   "source": [
    "Setting random seeds for all libraries. The seed for TF is a starting seed, and will get incremented with each call of Dropout(). Therefore, the notebook has to be restarted to get the same results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b36af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME = f\"dnn_human_chloridepotassium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10b8f4",
   "metadata": {},
   "source": [
    "Reading feature data from SVM notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da64614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing feature data from SVM notebooks (they have to be run first)\n",
    "import pickle\n",
    "with open(\"../data/tmp_data/svc_human_chloridepotassium_ml_data.pickle\", \"rb\") as handle:\n",
    "    ml_datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9672df1",
   "metadata": {},
   "source": [
    "Reading SVM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cebe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_svm = load_data(\"../data/results/svc_human_chloridepotassium.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bf016",
   "metadata": {},
   "source": [
    "Trying three different architectures, as the features have different sizes ranging from 400 to 8000. High dropout of 0.5 should take care of most overfitting problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938b300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e84093",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ml_datasets[0].y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45975d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d45f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9894e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, ml_dataset in enumerate(ml_datasets):\n",
    "    print(pos, ml_dataset.name, len(ml_dataset.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fc045",
   "metadata": {},
   "source": [
    "Using the same metrics as with the SVM, to compare the results better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_outer = {\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "    \"F1 Macro\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, average=\"macro\"\n",
    "    ),\n",
    "    \"F1 Class 0\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, pos_label=0\n",
    "    ),\n",
    "    \"F1 Class 1\": lambda y_test, y_pred: f1_score(\n",
    "        y_true=y_test, y_pred=y_pred, pos_label=1\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2a78e",
   "metadata": {},
   "source": [
    "Caching of results. A new test always needs a new test_name, otherwise it reads the old results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subpred.dnn import crossval_dnn, create_model\n",
    "from pathlib import Path\n",
    "if Path(f\"../data/results/{TEST_NAME}.pickle\").exists():\n",
    "    df_results_all = load_data(TEST_NAME, folder_path=\"../data/results\")\n",
    "else:\n",
    "    results = [\n",
    "        crossval_dnn(\n",
    "            ml_dataset=ml_dataset,\n",
    "            model_func=create_model,\n",
    "            scores_dict=scoring_outer,\n",
    "            splits=5,\n",
    "            repeats=5,\n",
    "            epochs=50,\n",
    "            batch_size=8,\n",
    "            calculate_class_weights=True\n",
    "        )\n",
    "        for ml_dataset in ml_datasets\n",
    "    ]\n",
    "    df_results_all = pd.concat(results)\n",
    "    save_results(df_results_all,TEST_NAME, folder_path=\"../data/results\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9f86c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ffc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same plot as for svm, to compare\n",
    "df_results_plot = df_results_all.copy()\n",
    "df_results_plot.Feature = df_results_plot.Feature.str.replace(\"_\", \"-\").replace(\"PSSM-META\",\"MULTI-PSSM\")\n",
    "df_results_plot = df_results_plot[~df_results_plot.Feature.str.match(r'^PSSM-\\d+')]\n",
    "df_results_plot = df_results_plot[~df_results_plot.Feature.str.startswith(\"COMB\")]\n",
    "feature_order = [\n",
    "    \"DUMMY\",\n",
    "    \"AAC\",\n",
    "    \"PAAC\",\n",
    "    \"AA-KMER3\",\n",
    "    # \"PSSM-50-1\",\n",
    "    # \"PSSM-50-3\",\n",
    "    # \"PSSM-90-1\",\n",
    "    # \"PSSM-90-3\",\n",
    "    # \"PSSM-META\",\n",
    "    \"MULTI-PSSM\",\n",
    "    \"META\",\n",
    "    \"META-STD\",\n",
    "    \"PROTT5-AA\",\n",
    "    \"PROSTT5-AA\",\n",
    "    \"PROSTT5-3DI\",\n",
    "    \"3Di-COMP\",\n",
    "    \"3Di-KMER2\",\n",
    "    \"3Di-KMER3\",\n",
    "    # \"COMB-KMER1\",\n",
    "    # \"COMB-KMER2\",\n",
    "    # \"COMB-KMER3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_plot.Feature.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4d993",
   "metadata": {},
   "source": [
    "saves plot with test name and metrics in name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_long(\n",
    "    df_results_long=df_results_plot,\n",
    "    output_folder_path=\"../data/results/\",\n",
    "    test_name=TEST_NAME,\n",
    "    plot_order=feature_order,\n",
    "    metrics_include=[\"F1 Class 0\", \"F1 Class 1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c99c1",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff62d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_results_all.copy()\n",
    "df_table.Feature = df_table.Feature.str.replace(\"_\", \"-\").replace(\"PSSM-META\",\"MULTI-PSSM\")\n",
    "df_table = df_table[~df_table.Feature.str.match(r'^PSSM-\\d+')]\n",
    "feature_order = [\n",
    "    \"DUMMY\",\n",
    "    \"AAC\",\n",
    "    \"PAAC\",\n",
    "    \"AA-KMER3\",\n",
    "    # \"PSSM-META\",\n",
    "    \"MULTI-PSSM\",\n",
    "    \"META\",\n",
    "    \"META-STD\",\n",
    "    \"COMB-KMER1\",\n",
    "    \"COMB-KMER2\",\n",
    "    \"COMB-KMER3\",\n",
    "    \"PROTT5-AA\",\n",
    "    \"PROSTT5-AA\",\n",
    "    \"PROSTT5-3DI\",\n",
    "    # \"PSSM-50-1\",\n",
    "    # \"PSSM-50-3\",\n",
    "    # \"PSSM-90-1\",\n",
    "    # \"PSSM-90-3\",\n",
    "    \"3Di-COMP\",\n",
    "    \"3Di-KMER2\",\n",
    "    \"3Di-KMER3\",\n",
    "]\n",
    "\n",
    "df_table_mean = df_table.groupby([\"Feature\", \"Metric\"]).mean().reset_index().pivot(\n",
    "    index=\"Feature\", columns=\"Metric\", values=\"Value\"\n",
    ")\n",
    "df_table_std = df_table.groupby([\"Feature\", \"Metric\"]).std().reset_index().pivot(\n",
    "    index=\"Feature\", columns=\"Metric\", values=\"Value\"\n",
    ")\n",
    "\n",
    "df_table_paper = df_table_mean.map(lambda x: f\"{x:.3f}\").astype(str) + \"Â±\" + df_table_std.map(lambda x: f\"{x:.3f}\").astype(str)\n",
    "df_table_paper = df_table_paper.loc[feature_order]\n",
    "df_table_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_paper.columns.name = None\n",
    "print(\n",
    "    df_table_paper.reset_index(drop=False)\n",
    "    .drop(\"F1 Macro\", axis=1)\n",
    "    .to_latex(index=False)\n",
    "    .replace(\"tabular\", \"tabular*\")\n",
    "    .replace(\"{llll}\", \"{\\\\textwidth}{@{\\\\extracolsep{\\\\fill}} lrrr}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15219298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
